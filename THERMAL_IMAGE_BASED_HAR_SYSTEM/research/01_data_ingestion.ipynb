{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGUARATION MANGER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dowNloading  zip files from google dive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def download_file(self)-> str:\n",
    "        '''\n",
    "        Fetch data from the url\n",
    "        '''\n",
    "\n",
    "        try: \n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix =  \"https://drive.google.com/uc?id=\"\n",
    "            gdown.download(prefix+file_id,zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file_id = dataset_url.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line extracts the **Google Drive file ID** from a URL.\n",
    "\n",
    " Example\n",
    "\n",
    "If the URL is:\n",
    "\n",
    "```python\n",
    "dataset_url = \"https://drive.google.com/file/d/1a2b3c4d5e6f7g8h9/view?usp=sharing\"\n",
    "```\n",
    "\n",
    "Then this line:\n",
    "\n",
    "```python\n",
    "file_id = dataset_url.split(\"/\")[-2]\n",
    "```\n",
    "\n",
    "will do the following:\n",
    "\n",
    "1. `dataset_url.split(\"/\")`\n",
    "   â†’ Splits the string by slashes `/`, giving:\n",
    "   `['https:', '', 'drive.google.com', 'file', 'd', '1a2b3c4d5e6f7g8h9', 'view?usp=sharing']`\n",
    "\n",
    "2. `[-2]`\n",
    "   â†’ Picks the second-to-last element, which is the file ID:\n",
    "   `'1a2b3c4d5e6f7g8h9'`\n",
    "\n",
    "---\n",
    "\n",
    " Why `[-2]`?\n",
    "\n",
    "* Google Drive links follow a pattern:\n",
    "  `.../d/<file_id>/...`\n",
    "  So `[-2]` gives the ID.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gdown.download(prefix+file_id,zip_download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://drive.google.com/uc?id=\"\n",
    "file_id = \"1a2b3c4d5e6f7g8h9\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading ZIP  from google drive HANDLING ERROR WITH MIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, logging, pathlib, mimetypes\n",
    "import gdown\n",
    "#from cnnClassifier.entity import DataIngestionConfig   # â† keep your import\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    # ------------ 1. download -----------------\n",
    "    def download_file(self) -> str:\n",
    "        \"\"\"\n",
    "        Downloads the file from Google-Drive link and returns local path.\n",
    "        \"\"\"\n",
    "        url  = self.config.source_URL\n",
    "        dest = self.config.local_data_file\n",
    "        os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "\n",
    "        logger.info(f\"â¬‡ï¸  Downloading {url}  â†’  {dest}\")\n",
    "        gdown.download(url, dest, quiet=False, fuzzy=True)\n",
    "        logger.info(\"âœ…  Download complete\")\n",
    "\n",
    "        return dest\n",
    "\n",
    "    # ------------ 2. extract ------------------\n",
    "    def extract_zip_file(self) -> None:\n",
    "        \"\"\"\n",
    "        Safely extracts `*.zip` archive to `unzip_dir`.\n",
    "        Raises ValueError if file is not a zip archive.\n",
    "        \"\"\"\n",
    "        zip_path  = pathlib.Path(self.config.local_data_file)\n",
    "        unzip_dir = pathlib.Path(self.config.unzip_dir)\n",
    "        unzip_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # âœ¨ Extra guard â€“ extension + MIME type\n",
    "        mime, _ = mimetypes.guess_type(zip_path)\n",
    "        if zip_path.suffix.lower() != \".zip\" or mime not in (\"application/zip\", \"application/x-zip-compressed\"):\n",
    "            msg = f\"{zip_path} is not a zip archive\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "                zf.extractall(unzip_dir)\n",
    "            logger.info(f\"ðŸ“¦  Extracted to {unzip_dir.resolve()}\")\n",
    "        except zipfile.BadZipFile as err:\n",
    "            msg = f\"Corrupted or non-zip file: {zip_path}\"\n",
    "            logger.exception(msg)\n",
    "            raise ValueError(msg) from err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def download_file(self)-> str:\n",
    "        '''\n",
    "        Fetch data from the url\n",
    "        '''\n",
    "\n",
    "        try: \n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix =  \"https://drive.google.com/uc?id=\"\n",
    "            gdown.download(prefix+file_id,zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data INGESTION PIPELINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-08 00:00:42,054: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-06-08 00:00:42,058: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-08 00:00:42,059: INFO: common: created directory at: artifacts]\n",
      "[2025-06-08 00:00:42,060: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-06-08 00:00:42,061: INFO: 767000518: Downloading data from https://drive.google.com/file/d/1BDVprz9NtenCp3wDovA2lfKVBzJDCTt2/view?usp=sharing into file artifacts/data_ingestion/data_2.zip]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1BDVprz9NtenCp3wDovA2lfKVBzJDCTt2\n",
      "From (redirected): https://drive.google.com/uc?id=1BDVprz9NtenCp3wDovA2lfKVBzJDCTt2&confirm=t&uuid=5428cea0-7c17-46d7-bb5b-06803a1ee85b\n",
      "To: /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/data_ingestion/data_2.zip\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.50G/1.50G [10:30<00:00, 2.39MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-08 00:11:18,535: INFO: 767000518: Downloaded data from https://drive.google.com/file/d/1BDVprz9NtenCp3wDovA2lfKVBzJDCTt2/view?usp=sharing into file artifacts/data_ingestion/data_2.zip]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
