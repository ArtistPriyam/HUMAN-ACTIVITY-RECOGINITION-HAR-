{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ab9f5e",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ccbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d34f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ThermalPoseProcessor:\n",
    "    def __init__(self, dataset_path, model_path):\n",
    "        \"\"\"\n",
    "        Initialize the thermal pose processing pipeline.\n",
    "        \n",
    "        Args:\n",
    "            dataset_path (str): Path to the dataset directory\n",
    "            model_path (str): Path to the trained YOLOv8-Pose model\n",
    "        \"\"\"\n",
    "        self.dataset_path = \"artifacts/OPEN_THERMAL_IMAGE/train\"\n",
    "        self.model_path = \"artifacts/model/openthermalpose\"\n",
    "        self.pose_model = None\n",
    "        self.classifier = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def load_pose_model(self):\n",
    "        \"\"\"Load the YOLOv8-Pose model\"\"\"\n",
    "        self.pose_model = YOLO(self.model_path)\n",
    "        print(\"Pose model loaded successfully.\")\n",
    "        \n",
    "    def load_and_prepare_data(self, test_size=0.2, val_size=0.1, random_state=42):\n",
    "        \"\"\"\n",
    "        Load the dataset and prepare train/val/test splits.\n",
    "        \n",
    "        Args:\n",
    "            test_size (float): Proportion of data for test set\n",
    "            val_size (float): Proportion of training data for validation set\n",
    "            random_state (int): Random seed for reproducibility\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing the splits (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \"\"\"\n",
    "        # Load activity labels\n",
    "        labels_path = os.path.join(self.dataset_path, 'activity_labels.csv')\n",
    "        df = pd.read_csv(labels_path)\n",
    "        \n",
    "        # Extract image paths and labels\n",
    "        image_paths = [os.path.join(self.dataset_path, 'train', img_name) \n",
    "                       for img_name in df['image_name']]\n",
    "        labels = df['activity_label'].values\n",
    "        \n",
    "        # Encode labels\n",
    "        y = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Split into train+val and test\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            image_paths, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "        \n",
    "        # Split train_val into train and val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=val_size/(1-test_size), \n",
    "            random_state=random_state, stratify=y_train_val)\n",
    "            \n",
    "        return {\n",
    "            'X_train': X_train,\n",
    "            'X_val': X_val,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'y_test': y_test\n",
    "        }\n",
    "    \n",
    "    def extract_keypoints(self, image_paths, batch_size=8):\n",
    "        \"\"\"\n",
    "        Extract pose keypoints from images using YOLOv8-Pose.\n",
    "        \n",
    "        Args:\n",
    "            image_paths (list): List of image paths to process\n",
    "            batch_size (int): Batch size for processing\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Array of keypoint vectors (n_samples, 51)\n",
    "        \"\"\"\n",
    "        if not self.pose_model:\n",
    "            raise ValueError(\"Pose model not loaded. Call load_pose_model() first.\")\n",
    "            \n",
    "        keypoint_vectors = []\n",
    "        \n",
    "        # Process images in batches\n",
    "        for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting keypoints\"):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            results = self.pose_model(batch_paths)\n",
    "            \n",
    "            for result in results:\n",
    "                if result.keypoints is not None and len(result.keypoints.xy) > 0:\n",
    "                    # Get the first person's keypoints (assuming single person per image)\n",
    "                    kpts = result.keypoints.xy[0].cpu().numpy().flatten()\n",
    "                    \n",
    "                    # If fewer than 17 keypoints, pad with zeros\n",
    "                    if len(kpts) < 51:  # 17 keypoints * 3 (x,y,confidence)\n",
    "                        kpts = np.pad(kpts, (0, 51 - len(kpts)))\n",
    "                    keypoint_vectors.append(kpts)\n",
    "                else:\n",
    "                    # If no keypoints detected, use zero vector\n",
    "                    keypoint_vectors.append(np.zeros(51))\n",
    "                    \n",
    "        return np.array(keypoint_vectors)\n",
    "    \n",
    "    def train_classifier(self, X_train, y_train, classifier_type='mlp'):\n",
    "        \"\"\"\n",
    "        Train a classifier on the extracted keypoint features.\n",
    "        \n",
    "        Args:\n",
    "            X_train (np.ndarray): Training features\n",
    "            y_train (np.ndarray): Training labels\n",
    "            classifier_type (str): Type of classifier ('mlp', 'random_forest')\n",
    "        \"\"\"\n",
    "        if classifier_type == 'mlp':\n",
    "            self.classifier = MLPClassifier(\n",
    "                hidden_layer_sizes=(128, 64), \n",
    "                activation='relu',\n",
    "                early_stopping=True,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif classifier_type == 'random_forest':\n",
    "            self.classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown classifier type: {classifier_type}\")\n",
    "            \n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        print(f\"{classifier_type.upper()} classifier trained successfully.\")\n",
    "    \n",
    "    def evaluate_classifier(self, X, y, split_name='validation'):\n",
    "        \"\"\"\n",
    "        Evaluate the classifier on given data.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Features to evaluate\n",
    "            y (np.ndarray): Ground truth labels\n",
    "            split_name (str): Name of the split for display purposes\n",
    "        \"\"\"\n",
    "        if not self.classifier:\n",
    "            raise ValueError(\"Classifier not trained. Call train_classifier() first.\")\n",
    "            \n",
    "        y_pred = self.classifier.predict(X)\n",
    "        report = classification_report(\n",
    "            y, \n",
    "            y_pred, \n",
    "            target_names=self.label_encoder.classes_\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{classifier_type.upper()} Performance on {split_name} set:\")\n",
    "        print(report)\n",
    "        return report\n",
    "    \n",
    "    def save_pipeline(self, output_dir):\n",
    "        \"\"\"Save the trained pipeline components\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        joblib.dump(self.classifier, os.path.join(output_dir, 'classifier.joblib'))\n",
    "        joblib.dump(self.label_encoder, os.path.join(output_dir, 'label_encoder.joblib'))\n",
    "        print(f\"Pipeline components saved to {output_dir}\")\n",
    "    \n",
    "    def load_pipeline(self, output_dir):\n",
    "        \"\"\"Load the trained pipeline components\"\"\"\n",
    "        self.classifier = joblib.load(os.path.join(output_dir, 'classifier.joblib'))\n",
    "        self.label_encoder = joblib.load(os.path.join(output_dir, 'label_encoder.joblib'))\n",
    "        print(f\"Pipeline components loaded from {output_dir}\")\n",
    "\n",
    "def run_pipeline(dataset_path, model_path, output_dir='saved_models', classifier_type='mlp'):\n",
    "    \"\"\"\n",
    "    Run the complete thermal pose activity recognition pipeline.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset directory\n",
    "        model_path (str): Path to the trained YOLOv8-Pose model\n",
    "        output_dir (str): Directory to save trained models\n",
    "        classifier_type (str): Type of classifier to use ('mlp' or 'random_forest')\n",
    "    \"\"\"\n",
    "    # Initialize the processor\n",
    "    processor = ThermalPoseProcessor(dataset_path, model_path)\n",
    "    \n",
    "    # Step 1: Load pose model\n",
    "    processor.load_pose_model()\n",
    "    \n",
    "    # Step 2: Prepare data splits\n",
    "    splits = processor.load_and_prepare_data()\n",
    "    \n",
    "    # Step 3: Extract keypoint features\n",
    "    print(\"\\nExtracting features from training set...\")\n",
    "    X_train_features = processor.extract_keypoints(splits['X_train'])\n",
    "    \n",
    "    print(\"\\nExtracting features from validation set...\")\n",
    "    X_val_features = processor.extract_keypoints(splits['X_val'])\n",
    "    \n",
    "    print(\"\\nExtracting features from test set...\")\n",
    "    X_test_features = processor.extract_keypoints(splits['X_test'])\n",
    "    \n",
    "    # Step 4: Train classifier\n",
    "    processor.train_classifier(X_train_features, splits['y_train'], classifier_type)\n",
    "    \n",
    "    # Step 5: Evaluate classifier\n",
    "    _ = processor.evaluate_classifier(X_train_features, splits['y_train'], 'training')\n",
    "    _ = processor.evaluate_classifier(X_val_features, splits['y_val'], 'validation')\n",
    "    test_report = processor.evaluate_classifier(X_test_features, splits['y_test'], 'test')\n",
    "    \n",
    "    # Step 6: Save pipeline\n",
    "    processor.save_pipeline(output_dir)\n",
    "    \n",
    "    return test_report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    dataset_path =  \"artifacts/OPEN_THERMAL_IMAGE/train\"\n",
    "    model_path = \"artifacts/model/openthermalpose/\"\n",
    "    \n",
    "    # Run with MLP classifier\n",
    "    print(\"Running pipeline with MLP classifier...\")\n",
    "    mlp_report = run_pipeline(dataset_path, model_path, classifier_type='mlp')\n",
    "    \n",
    "    # Run with Random Forest classifier\n",
    "    print(\"\\nRunning pipeline with Random Forest classifier...\")\n",
    "    rf_report = run_pipeline(dataset_path, model_path, classifier_type='random_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70736e6a",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160be0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 1.3112\n",
      "Epoch 2/20 - Loss: 1.1152\n",
      "Epoch 3/20 - Loss: 1.0734\n",
      "Epoch 4/20 - Loss: 1.0367\n",
      "Epoch 5/20 - Loss: 1.0150\n",
      "Epoch 6/20 - Loss: 0.9993\n",
      "Epoch 7/20 - Loss: 0.9875\n",
      "Epoch 8/20 - Loss: 0.9753\n",
      "Epoch 9/20 - Loss: 0.9682\n",
      "Epoch 10/20 - Loss: 0.9596\n",
      "Epoch 11/20 - Loss: 0.9570\n",
      "Epoch 12/20 - Loss: 0.9492\n",
      "Epoch 13/20 - Loss: 0.9419\n",
      "Epoch 14/20 - Loss: 0.9418\n",
      "Epoch 15/20 - Loss: 0.9351\n",
      "Epoch 16/20 - Loss: 0.9285\n",
      "Epoch 17/20 - Loss: 0.9232\n",
      "Epoch 18/20 - Loss: 0.9190\n",
      "Epoch 19/20 - Loss: 0.9155\n",
      "Epoch 20/20 - Loss: 0.9146\n",
      "[✓] Saved model to artifacts/classifiers/lstm_classifier.pt\n",
      "\n",
      "Test Accuracy: 0.8391\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "EXERCISE_BODY_SWING       0.64      0.90      0.75       185\n",
      "   LOOKING_STRAIGHT       1.00      0.99      0.99      1081\n",
      "   SITTING_STANDING       0.00      0.00      0.00        15\n",
      "           STANDING       0.00      0.00      0.00       129\n",
      "           fighting       0.08      0.03      0.04        36\n",
      "          gesturing       0.14      0.53      0.22        34\n",
      "            walking       0.81      0.81      0.81       671\n",
      "\n",
      "           accuracy                           0.84      2151\n",
      "          macro avg       0.38      0.47      0.40      2151\n",
      "       weighted avg       0.81      0.84      0.82      2151\n",
      "\n",
      "[✓] Saved report to artifacts/classifiers/eval_reports/lstm_evaluation.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# DL LSTM Classifier Training Pipeline\n",
    "# Author: Priyam\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Config\n",
    "# ------------------------------------------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    feature_dir: Path = Path(\"artifacts/pose_features\")\n",
    "    model_dir: Path = Path(\"artifacts/classifiers\")\n",
    "    report_dir: Path = Path(\"artifacts/classifiers/eval_reports\")\n",
    "    label_encoder_path: Path = model_dir / \"label_encoder.pkl\"\n",
    "\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 20\n",
    "    hidden_dim: int = 128\n",
    "    learning_rate: float = 1e-3\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def resolve_paths(self):\n",
    "        for attr in ['feature_dir', 'model_dir', 'report_dir']:\n",
    "            p = getattr(self, attr)\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "        return self\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Dataset\n",
    "# ------------------------------------------------------------\n",
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LSTM Classifier\n",
    "# ------------------------------------------------------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=51, hidden_dim=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming (batch_size, seq_len, input_dim)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(h_n[-1])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Training & Evaluation\n",
    "# ------------------------------------------------------------\n",
    "def train_model(cfg: Config):\n",
    "    cfg.resolve_paths()\n",
    "\n",
    "    # Load features\n",
    "    X_train = np.load(cfg.feature_dir / \"train.npy\")\n",
    "    X_test = np.load(cfg.feature_dir / \"test.npy\")\n",
    "    y_train = pd.read_csv(cfg.feature_dir / \"train_labels.csv\")[\"label\"].values\n",
    "    y_test = pd.read_csv(cfg.feature_dir / \"test_labels.csv\")[\"label\"].values\n",
    "\n",
    "    # Label encoding\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    joblib.dump(le, cfg.label_encoder_path)\n",
    "\n",
    "    # Dataset and loader\n",
    "    X_train_seq = X_train[:, None, :]  # shape: (N, 1, 51)\n",
    "    X_test_seq = X_test[:, None, :]\n",
    "\n",
    "    train_ds = PoseDataset(X_train_seq, y_train_enc)\n",
    "    test_ds = PoseDataset(X_test_seq, y_test_enc)\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=cfg.batch_size)\n",
    "\n",
    "    # Model\n",
    "    model = LSTMClassifier(input_dim=51, hidden_dim=cfg.hidden_dim, num_classes=len(le.classes_))\n",
    "    model.to(cfg.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(cfg.device), y_batch.to(cfg.device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{cfg.num_epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), cfg.model_dir / \"lstm_classifier.pt\")\n",
    "    print(f\"[✓] Saved model to {cfg.model_dir / 'lstm_classifier.pt'}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(cfg.device)\n",
    "            logits = model(X_batch)\n",
    "            preds = torch.argmax(logits, dim=1).cpu()\n",
    "            y_true.extend(y_batch.numpy())\n",
    "            y_pred.extend(preds.numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Fix for mismatched label sizes\n",
    "    present_labels = unique_labels(y_true, y_pred)\n",
    "    report = classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=present_labels,\n",
    "        target_names=le.inverse_transform(present_labels)\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    with open(cfg.report_dir / \"lstm_evaluation.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"[✓] Saved report to {cfg.report_dir / 'lstm_evaluation.txt'}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Entry point\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    train_model(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
