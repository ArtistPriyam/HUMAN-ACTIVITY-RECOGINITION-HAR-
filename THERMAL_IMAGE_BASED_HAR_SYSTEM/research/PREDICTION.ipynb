{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a51d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import os\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4dcc1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0378b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_1_frame154.png: 480x640 1 person, 57.8ms\n",
      "Speed: 2.2ms preprocess, 57.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_1_frame154.png: Unknown (EXERCISE_BODY_SWING)\n",
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_1_450_1.png: 480x640 1 person, 48.6ms\n",
      "Speed: 3.3ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_1_450_1.png: Unknown (LOOKING_STRAIGHT)\n",
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_1_frame136.png: 480x640 1 person, 53.5ms\n",
      "Speed: 0.6ms preprocess, 53.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_1_frame136.png: Unknown (EXERCISE_BODY_SWING)\n",
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_15_frame139.png: 480x640 1 person, 47.5ms\n",
      "Speed: 0.6ms preprocess, 47.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_15_frame139.png: Unknown (EXERCISE_BODY_SWING)\n",
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_0.png: 480x640 3 persons, 49.4ms\n",
      "Speed: 1.0ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_0.png: Unknown (gesturing)\n",
      "\n",
      "image 1/1 /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/TEST/1_1_1_15_frame220.png: 480x640 1 person, 49.4ms\n",
      "Speed: 0.6ms preprocess, 49.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1_1_1_15_frame220.png: Unknown (EXERCISE_BODY_SWING)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class HAR_Predictor:\n",
    "    def __init__(self, yolo_model_path: str, classifier_path: str, label_map: dict):\n",
    "        self.pose_model = YOLO(yolo_model_path)\n",
    "        self.classifier = joblib.load(classifier_path)\n",
    "        self.label_map = label_map  # Direct mapping from class index to label\n",
    "\n",
    "    def _extract_keypoints(self, result) -> np.ndarray:\n",
    "        try:\n",
    "            if not hasattr(result, 'keypoints') or result.keypoints is None:\n",
    "                return None\n",
    "            if result.keypoints.xy is None or len(result.keypoints.xy) == 0:\n",
    "                return None\n",
    "\n",
    "            # First person keypoints\n",
    "            xy = result.keypoints.xy[0].cpu().numpy()      # (17, 2)\n",
    "            conf = result.keypoints.conf[0].cpu().numpy()  # (17,)\n",
    "\n",
    "            img = cv2.imread(result.path)\n",
    "            h, w = img.shape[:2]\n",
    "            xy = xy / np.array([[w, h]])\n",
    "\n",
    "            if xy.shape != (17, 2) or conf.shape != (17,):\n",
    "                return None\n",
    "\n",
    "            vec = np.concatenate([xy.flatten(), conf])     # (51,)\n",
    "            return vec.astype(np.float32)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error extracting keypoints: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, image_path: str) -> str:\n",
    "        results = self.pose_model(image_path)\n",
    "        keypoint_vector = self._extract_keypoints(results[0])\n",
    "        if keypoint_vector is None:\n",
    "            return \"❌ No person detected or invalid keypoints\"\n",
    "\n",
    "        pred = self.classifier.predict(keypoint_vector.reshape(1, -1))[0]\n",
    "        label = self.label_map.get(pred, f\"Unknown ({pred})\")\n",
    "        return label\n",
    "\n",
    "# ======================\n",
    "# Inference\n",
    "# ======================\n",
    "\n",
    "# Create label map manually from activity_labels.csv\n",
    "label_map = {\n",
    "    0: \"walking\",\n",
    "    1: \"LOOKING_STRAIGHT\",\n",
    "    2: \"STANDING\",\n",
    "    3: \"jumping_climbing\",\n",
    "    4: \"suspicious_look\",\n",
    "    5: \"EXERCISE_BODY_SWING\",\n",
    "    6: \"SITTING_STANDING\",\n",
    "    7: \"fighting\",\n",
    "    8: \"gesturing\",\n",
    "    9: \"LOOKING_UP\"\n",
    "}\n",
    "\n",
    "pipeline = HAR_Predictor(\n",
    "    yolo_model_path=\"artifacts/weights/best.pt\",\n",
    "    classifier_path=\"artifacts/classifiers/mlp.pkl\",\n",
    "    label_map=label_map\n",
    ")\n",
    "\n",
    "test_dir = Path(\"artifacts/TEST\")\n",
    "image_exts = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "for img_path in test_dir.glob(\"*\"):\n",
    "    if img_path.suffix.lower() not in image_exts:\n",
    "        continue\n",
    "    result = pipeline.predict(str(img_path))\n",
    "    print(f\"{img_path.name}: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562835cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
