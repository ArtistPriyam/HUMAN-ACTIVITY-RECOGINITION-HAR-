{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2460f79",
   "metadata": {},
   "source": [
    "## label_csv formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bf0c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2006d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f6438c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4786198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_csv(csv_path: Path):\n",
    "    df = pd.read_csv(csv_path, header=None, names=['image', 'label'])\n",
    "    df['image'] = df['image'].apply(lambda x: Path(x).name)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "clean_csv(Path(\"artifacts/activity_labels_train.csv\"))\n",
    "clean_csv(Path(\"artifacts/activity_labels_test.csv\"))\n",
    "# If needed: clean_csv(Path(\"activity_labels_val.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fe824",
   "metadata": {},
   "source": [
    "# TRADITIONAL mlp and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d001013",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-pose summary (fused): 81 layers, 3,289,964 parameters, 0 gradients, 9.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 100%|██████████| 8845/8845 [11:59<00:00, 12.29it/s]   \n",
      "Extracting test: 100%|██████████| 2151/2151 [03:31<00:00, 10.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved trained classifier -> /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/classifiers/mlp.pkl\n",
      "Test accuracy: 0.8145\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "EXERCISE_BODY_SWING       0.78      0.86      0.82       185\n",
      "   LOOKING_STRAIGHT       0.90      0.99      0.95      1081\n",
      "   SITTING_STANDING       0.17      0.47      0.25        15\n",
      "           STANDING       0.00      0.00      0.00       129\n",
      "           fighting       0.57      0.22      0.32        36\n",
      "          gesturing       0.22      0.76      0.34        34\n",
      "            walking       0.82      0.71      0.76       671\n",
      "\n",
      "           accuracy                           0.81      2151\n",
      "          macro avg       0.50      0.57      0.49      2151\n",
      "       weighted avg       0.79      0.81      0.80      2151\n",
      "\n",
      "[✓] Saved evaluation report -> /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/classifiers/eval_reports/mlp_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Thermal Pose HAR Pipeline\n",
    "Author: priyam\n",
    "Description:\n",
    "    - Extracts 51‑dim keypoint feature vectors from thermal images using a trained YOLOv8‑Pose model.\n",
    "    - Trains a classification model (MLP or Random Forest) on those vectors to predict activity labels.\n",
    "    - Evaluates the classifier on the held‑out test split.\n",
    "    - Saves the evaluation report to artifacts/classifiers/eval_reports/ with filename format: MODELNAME_evaluation.txt\n",
    "\n",
    "Dataset structure (expected):\n",
    "    project_root/\n",
    "        artifacts/OPEN_THERMAL_IMAGE/\n",
    "            train/images/   (thermal .png/.jpg files)\n",
    "            test/images/\n",
    "        activity_labels_train.csv   (cols: image,label)\n",
    "        activity_labels_test.csv\n",
    "        weights/yolov8‑pose.pt      (trained pose model)\n",
    "\n",
    "All paths are configurable via the Config dataclass.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    project_root: Path = Path('.').resolve()\n",
    "\n",
    "    # Pose model\n",
    "    yolo_weights: Path = Path('artifacts/weights/best.pt')\n",
    "\n",
    "    # Image folders\n",
    "    train_dir: Path = Path('artifacts/OPEN_THERMAL_IMAGE/train/images')\n",
    "    test_dir: Path = Path('artifacts/OPEN_THERMAL_IMAGE/test/images')\n",
    "\n",
    "    # CSVs: <image file name>,<label>\n",
    "    train_csv: Path = Path('artifacts/activity_labels_train.csv')\n",
    "    test_csv: Path = Path('artifacts/activity_labels_test.csv')\n",
    "\n",
    "    # Output\n",
    "    feature_dir: Path = Path('artifacts/pose_features')\n",
    "    model_dir: Path = Path('artifacts/classifiers')\n",
    "    report_dir: Path = Path('artifacts/classifiers/eval_reports')\n",
    "\n",
    "    img_size: int = 640                     # inference size for YOLO\n",
    "    device: str = 'cpu'                     # or 'cuda'\n",
    "\n",
    "    def resolve_paths(self):\n",
    "        # Make all paths absolute relative to project_root\n",
    "        for attrib in ('yolo_weights', 'train_dir', 'test_dir',\n",
    "                       'train_csv', 'test_csv',\n",
    "                       'feature_dir', 'model_dir', 'report_dir'):\n",
    "            path = getattr(self, attrib)\n",
    "            if not path.is_absolute():\n",
    "                setattr(self, attrib, (self.project_root / path).resolve())\n",
    "\n",
    "        self.feature_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Pose extraction\n",
    "# ----------------------------------------------------------------------\n",
    "class PoseExtractor:\n",
    "    \"\"\"Runs YOLOv8‑Pose on images and returns a 51‑dim keypoint vector.\"\"\"\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.model = YOLO(str(cfg.yolo_weights))\n",
    "        self.model.fuse()  # speed\n",
    "\n",
    "    def _image_to_vec(self, img_path: Path) -> np.ndarray | None:\n",
    "        # Inference\n",
    "        results = self.model.predict(str(img_path),\n",
    "                                     imgsz=self.cfg.img_size,\n",
    "                                     device=self.cfg.device,\n",
    "                                     verbose=False)\n",
    "        if not results or len(results[0].keypoints) == 0:\n",
    "            return None\n",
    "\n",
    "        # Only the first detected person (index 0).\n",
    "        kp_xy = results[0].keypoints.xy[0].cpu().numpy()      # (17,2)\n",
    "        kp_conf = results[0].keypoints.conf[0].cpu().numpy()  # (17,)\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        h, w = img.shape[:2]\n",
    "        kp_xy_norm = kp_xy / np.array([[w, h]])\n",
    "\n",
    "        vec = np.concatenate([kp_xy_norm.flatten(), kp_conf])   # 17*2 + 17 = 51\n",
    "        return vec.astype(np.float32)\n",
    "\n",
    "    def extract_split(self, split: str, force: bool = False):\n",
    "        \"\"\"Returns (X, y) for a given split, caching .npy/.csv.\"\"\"\n",
    "        img_dir = getattr(self.cfg, f'{split}_dir')\n",
    "        csv_file = getattr(self.cfg, f'{split}_csv')\n",
    "        feat_npy = self.cfg.feature_dir / f'{split}.npy'\n",
    "        lbl_csv = self.cfg.feature_dir / f'{split}_labels.csv'\n",
    "\n",
    "        if feat_npy.exists() and lbl_csv.exists() and not force:\n",
    "            return np.load(feat_npy), pd.read_csv(lbl_csv)['label'].to_numpy()\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        vectors, labels = [], []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=f'Extracting {split}'):\n",
    "            img_fp = img_dir / row['image']\n",
    "            if not img_fp.exists():\n",
    "                print(f'Skip missing {img_fp}')\n",
    "                continue\n",
    "            vec = self._image_to_vec(img_fp)\n",
    "            if vec is not None:\n",
    "                vectors.append(vec)\n",
    "                labels.append(row['label'])\n",
    "\n",
    "        X = np.vstack(vectors)\n",
    "        y = np.array(labels)\n",
    "\n",
    "        np.save(feat_npy, X)\n",
    "        pd.DataFrame({'label': y}).to_csv(lbl_csv, index=False)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Classifier factory\n",
    "# ----------------------------------------------------------------------\n",
    "class ClassifierFactory:\n",
    "    @staticmethod\n",
    "    def get(name: str):\n",
    "        name = name.lower()\n",
    "        if name == 'mlp':\n",
    "            return MLPClassifier(hidden_layer_sizes=(128, 64),\n",
    "                                 activation='relu',\n",
    "                                 solver='adam',\n",
    "                                 max_iter=500,\n",
    "                                 random_state=42)\n",
    "        if name in ('rf', 'randomforest', 'random_forest'):\n",
    "            return RandomForestClassifier(n_estimators=400,\n",
    "                                          max_depth=None,\n",
    "                                          n_jobs=-1,\n",
    "                                          random_state=42)\n",
    "        raise ValueError(f'Unknown classifier {name}')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Training / evaluation pipeline\n",
    "# ----------------------------------------------------------------------\n",
    "class HARPipeline:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.cfg.resolve_paths()\n",
    "        self.extractor = PoseExtractor(cfg)\n",
    "\n",
    "    def run(self, clf_name: str = 'mlp', force_extract: bool = False):\n",
    "        # 1. Feature extraction\n",
    "        X_train, y_train = self.extractor.extract_split('train', force_extract)\n",
    "        X_test,  y_test  = self.extractor.extract_split('test',  force_extract)\n",
    "\n",
    "        # 2. Train classifier\n",
    "        clf = ClassifierFactory.get(clf_name)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # 3. Save\n",
    "        model_path = self.cfg.model_dir / f'{clf_name}.pkl'\n",
    "        joblib.dump(clf, model_path)\n",
    "        print(f'[✓] Saved trained classifier -> {model_path}')\n",
    "\n",
    "        # 4. Evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(f'Test accuracy: {acc:.4f}')\n",
    "        print(report)\n",
    "\n",
    "        # Save report\n",
    "        report_path = self.cfg.report_dir / f'{clf_name}_evaluation.txt'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f'Accuracy: {acc:.4f}\\n')\n",
    "            f.write(report)\n",
    "        print(f'[✓] Saved evaluation report -> {report_path}')\n",
    "\n",
    "        return clf\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Script entry‑point\n",
    "# ----------------------------------------------------------------------\n",
    "def main(clf='mlp', force=False, device='cpu', yolo_weights=None):\n",
    "    cfg = Config()\n",
    "    if yolo_weights:\n",
    "        cfg.yolo_weights = Path(yolo_weights)\n",
    "    cfg.device = device\n",
    "\n",
    "    pipeline = HARPipeline(cfg)\n",
    "    pipeline.run(clf, force)\n",
    "\n",
    "# Use this inside notebook directly:\n",
    "main(clf='mlp', force=True)  # or force=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f5c3d",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b44930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-pose summary (fused): 81 layers, 3,289,964 parameters, 0 gradients, 9.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 100%|██████████| 8845/8845 [14:31<00:00, 10.15it/s]   \n",
      "Extracting test: 100%|██████████| 2151/2151 [02:50<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved trained classifier -> /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/classifiers/mlp.pkl\n",
      "Test accuracy: 0.8145\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "EXERCISE_BODY_SWING       0.78      0.86      0.82       185\n",
      "   LOOKING_STRAIGHT       0.90      0.99      0.95      1081\n",
      "   SITTING_STANDING       0.17      0.47      0.25        15\n",
      "           STANDING       0.00      0.00      0.00       129\n",
      "           fighting       0.57      0.22      0.32        36\n",
      "          gesturing       0.22      0.76      0.34        34\n",
      "            walking       0.82      0.71      0.76       671\n",
      "\n",
      "           accuracy                           0.81      2151\n",
      "          macro avg       0.50      0.57      0.49      2151\n",
      "       weighted avg       0.79      0.81      0.80      2151\n",
      "\n",
      "[✓] Saved evaluation report -> /Users/priyam/DIL_LAB/HAR_HEAT_IMAGEdataset/artifacts/classifiers/eval_reports/mlp_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Thermal Pose HAR Pipeline\n",
    "Author: priyam\n",
    "Description:\n",
    "    - Extracts 51‑dim keypoint feature vectors from thermal images using a trained YOLOv8‑Pose model.\n",
    "    - Trains a classification model (MLP or Random Forest) on those vectors to predict activity labels.\n",
    "    - Evaluates the classifier on the held‑out test split.\n",
    "    - Saves the evaluation report to artifacts/classifiers/eval_reports/ with filename format: MODELNAME_evaluation.txt\n",
    "\n",
    "Dataset structure (expected):\n",
    "    project_root/\n",
    "        artifacts/OPEN_THERMAL_IMAGE/\n",
    "            train/images/   (thermal .png/.jpg files)\n",
    "            test/images/\n",
    "        activity_labels_train.csv   (cols: image,label)\n",
    "        activity_labels_test.csv\n",
    "        weights/yolov8‑pose.pt      (trained pose model)\n",
    "\n",
    "All paths are configurable via the Config dataclass.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    project_root: Path = Path('.').resolve()\n",
    "\n",
    "    # Pose model\n",
    "    yolo_weights: Path = Path('artifacts/weights/best.pt')\n",
    "\n",
    "    # Image folders\n",
    "    train_dir: Path = Path('artifacts/OPEN_THERMAL_IMAGE/train/images')\n",
    "    test_dir: Path = Path('artifacts/OPEN_THERMAL_IMAGE/test/images')\n",
    "\n",
    "    # CSVs: <image file name>,<label>\n",
    "    train_csv: Path = Path('artifacts/activity_labels_train.csv')\n",
    "    test_csv: Path = Path('artifacts/activity_labels_test.csv')\n",
    "\n",
    "    # Output\n",
    "    feature_dir: Path = Path('artifacts/pose_features')\n",
    "    model_dir: Path = Path('artifacts/classifiers')\n",
    "    report_dir: Path = Path('artifacts/classifiers/eval_reports')\n",
    "\n",
    "    img_size: int = 640                     # inference size for YOLO\n",
    "    device: str = 'cpu'                     # or 'cuda'\n",
    "\n",
    "    def resolve_paths(self):\n",
    "        # Make all paths absolute relative to project_root\n",
    "        for attrib in ('yolo_weights', 'train_dir', 'test_dir',\n",
    "                       'train_csv', 'test_csv',\n",
    "                       'feature_dir', 'model_dir', 'report_dir'):\n",
    "            path = getattr(self, attrib)\n",
    "            if not path.is_absolute():\n",
    "                setattr(self, attrib, (self.project_root / path).resolve())\n",
    "\n",
    "        self.feature_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Pose extraction\n",
    "# ----------------------------------------------------------------------\n",
    "class PoseExtractor:\n",
    "    \"\"\"Runs YOLOv8‑Pose on images and returns a 51‑dim keypoint vector.\"\"\"\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.model = YOLO(str(cfg.yolo_weights))\n",
    "        self.model.fuse()  # speed\n",
    "\n",
    "    def _image_to_vec(self, img_path: Path) -> np.ndarray | None:\n",
    "        # Inference\n",
    "        results = self.model.predict(str(img_path),\n",
    "                                     imgsz=self.cfg.img_size,\n",
    "                                     device=self.cfg.device,\n",
    "                                     verbose=False)\n",
    "        if not results or len(results[0].keypoints) == 0:\n",
    "            return None\n",
    "\n",
    "        # Only the first detected person (index 0).\n",
    "        kp_xy = results[0].keypoints.xy[0].cpu().numpy()      # (17,2)\n",
    "        kp_conf = results[0].keypoints.conf[0].cpu().numpy()  # (17,)\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        h, w = img.shape[:2]\n",
    "        kp_xy_norm = kp_xy / np.array([[w, h]])\n",
    "\n",
    "        vec = np.concatenate([kp_xy_norm.flatten(), kp_conf])   # 17*2 + 17 = 51\n",
    "        return vec.astype(np.float32)\n",
    "\n",
    "    def extract_split(self, split: str, force: bool = False):\n",
    "        \"\"\"Returns (X, y) for a given split, caching .npy/.csv.\"\"\"\n",
    "        img_dir = getattr(self.cfg, f'{split}_dir')\n",
    "        csv_file = getattr(self.cfg, f'{split}_csv')\n",
    "        feat_npy = self.cfg.feature_dir / f'{split}.npy'\n",
    "        lbl_csv = self.cfg.feature_dir / f'{split}_labels.csv'\n",
    "\n",
    "        if feat_npy.exists() and lbl_csv.exists() and not force:\n",
    "            return np.load(feat_npy), pd.read_csv(lbl_csv)['label'].to_numpy()\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        vectors, labels = [], []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=f'Extracting {split}'):\n",
    "            img_fp = img_dir / row['image']\n",
    "            if not img_fp.exists():\n",
    "                print(f'Skip missing {img_fp}')\n",
    "                continue\n",
    "            vec = self._image_to_vec(img_fp)\n",
    "            if vec is not None:\n",
    "                vectors.append(vec)\n",
    "                labels.append(row['label'])\n",
    "\n",
    "        X = np.vstack(vectors)\n",
    "        y = np.array(labels)\n",
    "\n",
    "        np.save(feat_npy, X)\n",
    "        pd.DataFrame({'label': y}).to_csv(lbl_csv, index=False)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Classifier factory\n",
    "# ----------------------------------------------------------------------\n",
    "class ClassifierFactory:\n",
    "    @staticmethod\n",
    "    def get(name: str):\n",
    "        name = name.lower()\n",
    "        if name == 'mlp':\n",
    "            return MLPClassifier(hidden_layer_sizes=(128, 64),\n",
    "                                 activation='relu',\n",
    "                                 solver='adam',\n",
    "                                 max_iter=500,\n",
    "                                 random_state=42)\n",
    "        if name in ('rf', 'randomforest', 'random_forest'):\n",
    "            return RandomForestClassifier(n_estimators=400,\n",
    "                                          max_depth=None,\n",
    "                                          n_jobs=-1,\n",
    "                                          random_state=42)\n",
    "        raise ValueError(f'Unknown classifier {name}')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Training / evaluation pipeline\n",
    "# ----------------------------------------------------------------------\n",
    "class HARPipeline:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.cfg.resolve_paths()\n",
    "        self.extractor = PoseExtractor(cfg)\n",
    "\n",
    "    def run(self, clf_name: str = 'mlp', force_extract: bool = False):\n",
    "        # 1. Feature extraction\n",
    "        X_train, y_train = self.extractor.extract_split('train', force_extract)\n",
    "        X_test,  y_test  = self.extractor.extract_split('test',  force_extract)\n",
    "\n",
    "        # 2. Train classifier\n",
    "        clf = ClassifierFactory.get(clf_name)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # 3. Save\n",
    "        model_path = self.cfg.model_dir / f'{clf_name}.pkl'\n",
    "        joblib.dump(clf, model_path)\n",
    "        print(f'[✓] Saved trained classifier -> {model_path}')\n",
    "\n",
    "        # 4. Evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(f'Test accuracy: {acc:.4f}')\n",
    "        print(report)\n",
    "\n",
    "        # Save report\n",
    "        report_path = self.cfg.report_dir / f'{clf_name}_evaluation.txt'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f'Accuracy: {acc:.4f}\\n')\n",
    "            f.write(report)\n",
    "        print(f'[✓] Saved evaluation report -> {report_path}')\n",
    "\n",
    "        return clf\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Script entry‑point\n",
    "# ----------------------------------------------------------------------\n",
    "def main(clf='rf', force=True, device='cpu', yolo_weights=None):\n",
    "    cfg = Config()\n",
    "    if yolo_weights:\n",
    "        cfg.yolo_weights = Path(yolo_weights)\n",
    "    cfg.device = device\n",
    "\n",
    "    pipeline = HARPipeline(cfg)\n",
    "    pipeline.run(clf, force)\n",
    "\n",
    "# Use this inside notebook directly:\n",
    "main(clf='mlp', force=True)  # or force=False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
